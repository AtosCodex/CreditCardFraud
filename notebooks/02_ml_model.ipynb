{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from google.datalab.ml import TensorBoard\n",
    "\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure logging\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "pd.options.display.max_rows = 50\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = './trained_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes result reproducible\n",
    "#np.random.seed(seed=1) \n",
    "#tf.random.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/preprocess/creditcard_train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./data/preprocess/creditcard_test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_COLUMNS = [\n",
    "  tf.feature_column.numeric_column(\"Time\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V1\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V2\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V3\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V4\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V5\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V6\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V7\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V9\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V10\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V11\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V12\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V14\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V16\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V17\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V18\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V19\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V21\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"Amount\", dtype=tf.float32)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDITIONAL_COLUMNS = [\n",
    "  tf.feature_column.numeric_column(\"V1_\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V2_\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V3_\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V4_\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V5_\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V6_\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V7_\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V9_\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V10_\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V11_\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V12_\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V14_\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V16_\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V17_\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V18_\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V19_\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"V21_\", dtype=tf.float32),\n",
    "  tf.feature_column.numeric_column(\"Amount_max_fraud\", dtype=tf.float32)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your feature columns\n",
    "def create_feature_cols():\n",
    "  return INPUT_COLUMNS + ADDITIONAL_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_more_features(df):\n",
    "  \"Add additional features\"\n",
    "  # ToDo Add additional standardized columns\n",
    "  df['Amount_max_fraud'] = 1\n",
    "  df.loc[df.Amount <= 2125.87, 'Amount_max_fraud'] = 0\n",
    "  df['V1_'] = df.V1.map(lambda x: 1 if x < -3 else 0)\n",
    "  df['V2_'] = df.V2.map(lambda x: 1 if x > 2.5 else 0)\n",
    "  df['V3_'] = df.V3.map(lambda x: 1 if x < -4 else 0)\n",
    "  df['V4_'] = df.V4.map(lambda x: 1 if x > 2.5 else 0)\n",
    "  df['V5_'] = df.V5.map(lambda x: 1 if x < -4.5 else 0)\n",
    "  df['V6_'] = df.V6.map(lambda x: 1 if x < -2.5 else 0)\n",
    "  df['V7_'] = df.V7.map(lambda x: 1 if x < -3 else 0)\n",
    "  df['V9_'] = df.V9.map(lambda x: 1 if x < -2 else 0)\n",
    "  df['V10_'] = df.V10.map(lambda x: 1 if x < -2.5 else 0)\n",
    "  df['V11_'] = df.V11.map(lambda x: 1 if x > 2 else 0)\n",
    "  df['V12_'] = df.V12.map(lambda x: 1 if x < -2 else 0)\n",
    "  df['V14_'] = df.V14.map(lambda x: 1 if x < -2.5 else 0)\n",
    "  df['V16_'] = df.V16.map(lambda x: 1 if x < -2 else 0)\n",
    "  df['V17_'] = df.V17.map(lambda x: 1 if x < -2 else 0)\n",
    "  df['V18_'] = df.V18.map(lambda x: 1 if x < -2 else 0)\n",
    "  df['V19_'] = df.V19.map(lambda x: 1 if x > 1.5 else 0)\n",
    "  df['V21_'] = df.V21.map(lambda x: 1 if x > 0.6 else 0)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_feature_cols(df):\n",
    "  \"\"\"\n",
    "  Transform each feature in features so that it has a mean of 0 and standard deviation of 1; \n",
    "  This helps with training the neural network.\n",
    "  \"\"\"\n",
    "  features = df.columns.values\n",
    "  for feature in features:\n",
    "    if feature != 'Class':\n",
    "      mean, std = df[feature].mean(), df[feature].std()\n",
    "      df.loc[:, feature] = (df[feature] - mean) / std\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(df):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = transform_feature_cols(add_more_features(df)),\n",
    "    y = df['Class'],\n",
    "    batch_size = 256,\n",
    "    num_epochs = None,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_fn(df):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = transform_feature_cols(add_more_features(df)),\n",
    "    y = df['Class'],\n",
    "    batch_size = 128,\n",
    "    num_epochs = 1,\n",
    "    shuffle = False,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "  \"\"\"Servers prediction service\"\"\"\n",
    "  feature_placeholders = {\n",
    "      column.name: tf.placeholder(tf.float32, [None]) for column in INPUT_COLUMNS\n",
    "  }\n",
    "  features = add_more_features(pd.DataFrame.from_dict(feature_placeholders.copy()))\n",
    "  return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo impelement for custom estimator\n",
    "def dnn_model(img, mode, hparams):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo impelement for custom estimator\n",
    "def transaction_classifier(features, labels, mode, params):\n",
    "  \"\"\"Transaction classifier either fraud or normal\"\"\"\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "  \"\"\"Training and evalucation function\"\"\"\n",
    "  EVAL_INTERVAL = 10\n",
    "  feature_columns = create_feature_cols()\n",
    "  estimator = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[37, 18, 9],\n",
    "    optimizer=tf.train.AdamOptimizer(1e-4),\n",
    "    n_classes=2,\n",
    "    dropout=0.1,\n",
    "    model_dir=output_dir)\n",
    "    \n",
    "  train_spec=tf.estimator.TrainSpec(input_fn=train_input_fn(df_train), max_steps=num_train_steps)\n",
    "  # ToDo Fix issue of add engg feature with panda read input functions\n",
    "  # exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "  eval_spec=tf.estimator.EvalSpec(input_fn=eval_input_fn(df_test), throttle_secs=EVAL_INTERVAL, exporters=exporter)\n",
    "  \n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch tensorboard\n",
    "#TensorBoard().start(OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True)\n",
    "train_and_evaluate(OUTDIR, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "# Copyright 2018 Atos. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
